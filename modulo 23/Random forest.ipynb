{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d183e3e4",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Monte um passo a passo para o algoritmo RF\n",
    "\n",
    "Passo 1. Bootstrap + feature selection - Fazer o bootstrap nas linhas e o feature selection(selecionar aleatoriamente x colunas) nas colunas\n",
    "\n",
    "Passo 2. Modelagem com arvores de decisão - nessa etapa fazemos os modelos para cada amostra Booststrap selecionadas na etapa anterior\n",
    "\n",
    "\n",
    "passo 3. Agregação - nessa etapa fazemos a agregação dos resultados de cada modelo, caso seja problema de classificação a agregação é feita pelo voto majoritário onde os modelos com maior frequência é selecionado como  resultado.\n",
    "Em caso de modelo de regressão é feito a média dos resultados\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Explique com suas palavras o Random Forest\n",
    "\n",
    "Diferente de uma arvore simples no random forest o primeiro passo do algoritmo é selecionar algumas amostras aleatórias dos dados de treino, usando o bootstrap que é um método de reamostragem onde as amostras podem se repetir no dataframe. Pode se construir quantas arvores quiser, quanto mais arvores melhor será o modelo e maior o processamento.\n",
    "com o modelo devidamente criado podemos passar a ele novos dados de teste cada arvore irá apresentar seu resultado e no final o algoritimo fará a agregação, sendo a media dos resultados para problemas de regressão e voto majoritário para problemas de classificação\n",
    "\n",
    "\n",
    "#### 3. Qual a diferença entre Bagging e Random Forest?\n",
    "\n",
    "\n",
    "A principal diferença entre o Bagging e o bootstrap é a forma como eles criam os conjuntos de dados aleatorios\n",
    "enquanto o Bagging seleciona aleatoriamente as linhas do dataframe principal o Random forest seleciona as colunas isso resulta em dados divesificados que podem melhorar o modelo e evitar overfiting.\n",
    "<blockquote>\n",
    "<p>Em conclusão, Bagging e Random forest são dois métodos populares de aprendizado de conjunto que usam várias árvores</p> \n",
    "<p>de decisão para melhorar a precisão de um modelo. Ambos os métodos introduzem aleatoriedade no conjunto de dados para</p> <p>reduzir a variância do modelo e evitar o overfitting</p>\n",
    "</blockquote>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
